<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Método de Monte Carlo via Cadeias de Markov – Estatística Computacional I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./monte_carlo.html" rel="next">
<link href="./AR.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-364982630eef5352dd1537128a8ed5cb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./mcmc.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Método de Monte Carlo via Cadeias de Markov</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Estatística Computacional I</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./solucoes_caso_real.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Solução de equações</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./otimizacao.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Métodos de otimização</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./integral.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos de quadratura</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gerador_congruencial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introdução aos geradores de números pseudo-aleatórios</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inversao.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Método da inversão</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./uniforme_multivariada.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Método da uniforme multivariada com marginais não uniformes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./AR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">O método da aceitação/rejeição</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mcmc.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Método de Monte Carlo via Cadeias de Markov</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./monte_carlo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">O método de integração de Monte Carlo</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./provas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Provas</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introdução-à-cadeias-de-markov" id="toc-introdução-à-cadeias-de-markov" class="nav-link active" data-scroll-target="#introdução-à-cadeias-de-markov"><span class="header-section-number">8.1</span> Introdução à Cadeias de Markov</a></li>
  <li><a href="#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov-mcmc" id="toc-introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov-mcmc" class="nav-link" data-scroll-target="#introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov-mcmc"><span class="header-section-number">8.2</span> Introdução aos Métodos de Monte Carlo via Cadeias de Markov (MCMC)</a></li>
  <li><a href="#o-método-metropolis-hastings" id="toc-o-método-metropolis-hastings" class="nav-link" data-scroll-target="#o-método-metropolis-hastings"><span class="header-section-number">8.3</span> O método Metropolis-Hastings</a>
  <ul class="collapse">
  <li><a href="#a-escolha-da-proposta-e-o-parâmetro-tunning" id="toc-a-escolha-da-proposta-e-o-parâmetro-tunning" class="nav-link" data-scroll-target="#a-escolha-da-proposta-e-o-parâmetro-tunning"><span class="header-section-number">8.3.1</span> A escolha da proposta e o parâmetro <em>tunning</em></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Método de Monte Carlo via Cadeias de Markov</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introdução-à-cadeias-de-markov" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="introdução-à-cadeias-de-markov"><span class="header-section-number">8.1</span> Introdução à Cadeias de Markov</h2>
<p>A coleção <span class="math inline">\(\{X(t),t\in T\}\)</span> é um processo estocástico se <span class="math inline">\(X(t)\)</span> é uma variável aleatória para cada <span class="math inline">\(t\inT\)</span>. A variável <span class="math inline">\(X(t)\)</span> é denominada estado. O processo é dito ser a tempo discreto se <span class="math inline">\(T\subseteq \mathbb{Z}\)</span>.</p>
<p>Em um processo a tempo discreto, é usual utilizar a notação <span class="math inline">\(X(t)\equiv X_t\)</span>.</p>
<p>O processo estocástico <span class="math inline">\(\{\ldots,X_1,X_0,X_1,X_2,\ldots\}\)</span> é uma cadeia de Markov de ordem <span class="math inline">\(d\)</span> se</p>
<p><span class="math display">\[P(X_n\in A|X_{n−1}=x_{n−1},\ldots,X_0=x_0)=P(X_n\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d}).\]</span></p>
<p>Uma cadeia de Markov é dita ser homogênea se, para qualquer <span class="math inline">\(m&gt;0\)</span> natural,</p>
<p><span class="math display">\[P(X_n\in A|X_{n−1}=x_{n−1},…,X_{n−d}=x_{n−d})=P(X_{n+m}\in A|X_{n+m−1}=x_{n−1},…,X_{n+m−d}=x_{n−d}).\]</span> Estamos interessados nas cadeias homogêneas de ordem <span class="math inline">\(d=1\)</span>, que doravante serão denominadas simplesmente por cadeias de Markov.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.1</strong></span> Considere a seguinte cadeia de Markov:</p>
<p><span class="math display">\[X_{n}|X_{n−1}=y∼\hbox{Uniforme}(1−y,1).\]</span></p>
<p>Abaixo, simulamos duas trajetórias deste processo, cada uma com um valor diferente para <span class="math inline">\(x_0\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># pontos iniciais as trajetórias</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x_1 <span class="ot">&lt;-</span> .<span class="dv">01</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>x_2 <span class="ot">&lt;-</span> .<span class="dv">99</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">100</span>){</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  x_1[i] <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">-</span> x_1 [i <span class="sc">-</span> <span class="dv">1</span>] , <span class="dv">1</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  x_2[i] <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="dv">1</span> <span class="sc">-</span> x_2 [i <span class="sc">-</span> <span class="dv">1</span>] , <span class="dv">1</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># gráfico das duas trajetórias</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x_1, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x_2, <span class="at">type=</span><span class="st">'l'</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-1-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x_1,x_2, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span><span class="dv">1</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x_1[<span class="dv">1</span>] , x_2[<span class="dv">1</span>] , <span class="at">pch=</span><span class="dv">16</span>) <span class="co"># ponto inicial</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-1-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<p>A evolução da cadeia de <span class="math inline">\(X_n\)</span> até <span class="math inline">\(X_{n+1}\)</span> é denominada transição 1 -passos à frente. A densidade <span class="math inline">\(k(.|y)\)</span> que satisfaz</p>
<p><span class="math display">\[P(X_{n+1}\in A|X_n=y)=\int_A k(x|y)dx\]</span></p>
<p>é denominada núcleo de transição (ou núcleo de transição 1 -passo à frente). De maneira análoga, a densidade <span class="math inline">\(k^{(d)}(.|y)\)</span> que que satisfaz</p>
<p><span class="math display">\[P(X_{n+d}\in A|X_{n}=y)=\int_A k^{(d)}(x|y)dx\]</span> é denominada núcleo de transição <span class="math inline">\(d\)</span>-passos à frente.</p>
<div class="alert alert-success">
<p><strong>Equações de Chapman-Kolmogorov</strong> Para qualquer <span class="math inline">\(0&lt;m&lt;n\)</span> tem-se que</p>
<p><span class="math display">\[k^{(n)}(x|y)=\int_{\mathbb{R}} k^{(m)}(x|u)k^{(n−m)}(u|y)du.\]</span></p>
</div>
<p>Dizemos que <span class="math inline">\(\pi(.)\)</span> é a densidade da distribuição estacionária de uma cadeia de Markov se</p>
<p><span class="math display">\[\pi(y)=\int_{\mathbb{R}} \pi(x)k(y|x)dx,\]</span> ou seja a distribuição estacionária é a distribuição marginal do processo. Como</p>
<p><span class="math display">\[\begin{align}\int_{\mathbb{R}}\pi(x)k^{(2)}(y|x)dx&amp;=\int_{\mathbb{R}}\pi(x)\int_{\mathbb{R}}k(y|u)k(u|x)dudx\\&amp;=\int_{\mathbb{R}}k(y|u)[\int_{\mathbb{R}}\pi(x)k(u|x)dx]du\\&amp;=\int_{\mathbb{R}}k(y|u)\pi(u)du=\pi(y)\end{align}\]</span> é simples mostrar por indução que <span class="math inline">\(\pi(.)\)</span> satisfaz</p>
<p><span class="math display">\[\pi(y)=\int_{\mathbb{R}}\pi(x)k^{(n)}(y|x)dx.\]</span></p>
<p>Suponha que valem as seguintes afirmações:</p>
<ol type="1">
<li><p>Existe <span class="math inline">\(n&gt;0\)</span> tal que <span class="math inline">\(P(X_n\in A|X_0=x_0)\)</span> para quaisquer <span class="math inline">\(A\)</span> e <span class="math inline">\(x_0\)</span>. Além disso, o número médio de passos para realizar a transição é finito.</p></li>
<li><p><span class="math inline">\(P(X_n\in A|X_0=x_0)\)</span> não é uma função periódica em <span class="math inline">\(n\)</span>.</p></li>
</ol>
<p>Então, faz sentido em falar sobre</p>
<p><span class="math display">\[\lim_{n\rightarrow \infty}k^{(n)}(x|y).\]</span></p>
<p>Sob as condições acima, a única densidade que satifaz esse limite é distribuição estacionária, isto é,</p>
<p><span class="math display">\[\lim_{n\rightarrow \infty}k^{(n)}(x|y)=\pi(x).\]</span></p>
<p>A seguinte definição será útil adiante.</p>
<div id="def-" class="alert alert-success theorem definition">
<p><span class="theorem-title"><strong>Definition 8.1</strong></span> Dizemos que uma cadeia de Markov com núcleo de transição <span class="math inline">\(k(x|y)\)</span> é reversível com relação à <span class="math inline">\(\pi(x)\)</span> se</p>
<p><span class="math display">\[\pi(x)k(y|x)=\pi(y)k(x|y)\]</span> para todo <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> no espaço dos estados. A equação acima é conhecida como balanço detalhado.</p>
</div>
<p>Nem toda cadeia de Markov seja reversível em relação à sua distribuição estacionária. Contudo, se vale equação de balanço detalalhado para alguma função densidade <span class="math inline">\(\pi(.)\)</span> qualquer, então esta é a distribuição estacionária, pois</p>
<p><span class="math display">\[\int_{\mathbb{R}}\pi(x)k(y|x)dx=\int_{\mathbb{R}}\pi(y)k(x|y)dx=\pi(y)\]</span>.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.2</strong></span> Considere novamente a seguinte cadeia de Markov:</p>
<p><span class="math display">\[X_n|X_{n−1}=y∼Uniforme(1−y,1),\]</span> ou seja <span class="math display">\[k(x|y)=\frac{1}{y}I(1-y&lt;x&lt;1).\]</span></p>
<p>Vamos mostrar que sua distribuição estacionária é <span class="math inline">\(\pi(x)=2x\)</span>, com <span class="math inline">\(x\in(0,1)\)</span>. Observe que</p>
<p><span class="math display">\[\begin{align}
\pi(y)k(x|y)&amp;=2yI(0&lt;y&lt;1)\frac{1}{y}I(1-y&lt;x&lt;1)=I(0&lt;y&lt;1)I(1-y&lt;x&lt;1)\\&amp;=I(0&lt;y&lt;1)I(1-x&lt;y&lt;1+y-x)=I(1-x&lt;y&lt;1),\end{align}\]</span> e que <span class="math display">\[\begin{align}
\pi(x)k(y|x)&amp;=2x\frac{1}{x}I(0&lt;x&lt;1)I(1-x&lt;y&lt;1)=I(1-x&lt;y&lt;1),\end{align}\]</span></p>
<p>logo, a equações de balanço detalhado estão satisfeitas.</p>
<p>Portanto, o comportamento marginal de uma trajetória simulada deve se comportar como a distribuição estacionária. Abaixo simulammos uma trajetória de tamanho 5000 e mostramos o seu histograma em conjunto com a densidade da distribuição estacionária,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">3</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">5000</span>) x[i] <span class="ot">&lt;-</span> <span class="fu">runif</span>( <span class="dv">1</span>, <span class="dv">1</span><span class="sc">-</span>x[i<span class="dv">-1</span>])</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>d_estacionaria <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="sc">*</span>x</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">d_estacionaria</span>(x), <span class="at">add =</span> T , <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov-mcmc" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="introdução-aos-métodos-de-monte-carlo-via-cadeias-de-markov-mcmc"><span class="header-section-number">8.2</span> Introdução aos Métodos de Monte Carlo via Cadeias de Markov (MCMC)</h2>
<p>Os métodos para simular a distribuição <span class="math inline">\(f(x)\)</span> gerando variáveis aleatórias utilizando uma cadeia de Markov são denominados métodos de Monte Carlo via Cadeias de Markov (MCMC).</p>
<p>Diferente dos outros métodos de simulação, os MCMCs exigem alguns cuidados adicionais para garantir que estamos simulando variáveis independentes e identicamente distribuídas.</p>
<p>Ao longo desta seção, vamos utilizar a cadeia do exemplo abaixo.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.3</strong></span> Considere uma cadeia de Markov com o seguinte núcleo de transição,</p>
<p><span class="math display">\[X_t|X_{t−1}=y∼N(\alpha y,1)\]</span></p>
<p>com <span class="math inline">\(\alpha\in(−1,1)\)</span>. Pode-se provar que sua distribuição estacionária é a distribuição Normal(0,<span class="math inline">\(1/(1-\alpha)\)</span>). Ao longo desta seção, utilizaremos <span class="math inline">\(\alpha=0,7\)</span>.</p>
</div>
<p>O objetivo dos métodos do tipo MCMC é desenvolver uma cadeia de Markov, com certo núcleo de transição <span class="math inline">\(k(x_{i}|x_{i−1})\)</span> que tenha como distribuição estacionária a distribuição de interesse, doravante denotada por <span class="math inline">\(f(x)\)</span>.</p>
<p>Em tese, bastaria gerar uma trajetória da cadeia utilizando o núcleo de transição para obter amostras de <span class="math inline">\(f(x)\)</span>. Como a trajetória deve começar em um ponto <span class="math inline">\(x_0\)</span>, existem duas situações:</p>
<ul>
<li><p><span class="math inline">\(x_0\)</span> é escolhida na região de alta densidade de <span class="math inline">\(f(x)\)</span>: nesse caso, os pontos simulados pelo processo terão distribuição marginal igual à <span class="math inline">\(f(x)\)</span></p></li>
<li><p><span class="math inline">\(x_0\)</span> é escolhida fora da região de alta densidade de <span class="math inline">\(f(x)\)</span>: nesse caso, a trajetória inicial não deve corresponder à distribuição de <span class="math inline">\(f(x)\)</span>. Entretanto, como</p></li>
</ul>
<p><span class="math display">\[f(x)=\lim_{n\rightarrow\infty} k^{(n)}(x|x_0)\]</span> existe um momento no qual a patir dele, a trajetória vai começar a simular pontos de <span class="math inline">\(f(x)\)</span>.</p>
<p>Quando das características de <span class="math inline">\(f(x)\)</span> são desconhecidas, é boa prática comelcar a simular diversas cadeias començando em pontos distintos. O gráfico de linha (<em>traceplot</em>), que é um gráfico do tempo do processo contra os valores simulados, é útil para verificar a convergência, uma vez que todas as trajetórias devem se encontrar em algum momento.</p>
<p>O traceplot de um processo estacionário com variância finita tem um comportamento típico de pontos em torno da média da distribuição estacionária. Deste modo, ele é uma ferramenta exploratória que nos auxilia a detectar se a cadeia não está em equilíbrio ao perceber um padrão fora do que se esperaria de uma distribuição estacionária.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.4</strong></span> Abaixo, ilustramos o traceplot de duas cadeias simuladas, sendo que a única diferença entre elas é o valor de <span class="math inline">\(x_0\)</span>. A distribuição estacionária está representada ao longo do eixo das ordenadas com as linhas tracejadas em azul representando os quantis 99,5% e 0,05%. Mostramos dois traceplots (linhas pretas) com valores distintos de <span class="math inline">\(x_0\)</span>. No primeiro, escolhemos <span class="math inline">\(x_0=0\)</span> que é a média da distribuição estacionária e na segunda <span class="math inline">\(x_0=−10\)</span>, um valor extremo.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="traceplot1_intro.png" class="img-fluid figure-img"></p>
<figcaption>Trajetória começando na média de <span class="math inline">\(f(x)\)</span></figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="traceplot2_intro.png" class="img-fluid figure-img"></p>
<figcaption>Trajetória começando distante da região de alta densidade de <span class="math inline">\(f(x)\)</span></figcaption>
</figure>
</div>
<p>Com <span class="math inline">\(x_0=0\)</span>, o traceplot não dá evidências contra a hipótese de equilíbrio, pois os pontos simulados condizem com o que é esperado para a distribuição estacionária. Já com <span class="math inline">\(x_0=−10\)</span>, temos que o traceplot dá evidências de que a convergência ocorreu após 3 ou 4 iterações.</p>
</div>
<p>O exemplo acima nos mostra que os métodos do tipo MCMC são sensíveis aos valores iniciais. Note que no exemplo dado foi trivial decidir que <span class="math inline">\(x_0=0\)</span> era uma escolha adequada, mas para distribuições multivariadas isso pode ser um desafio. Portanto, é usual considerar que as primeiras simulações sempre estão erradas e as descartamos. Esse processo é denominado <em>burn-in</em>. Não há uma proporção recomendada para o <em>burn-in</em> embora em geral uma inspeção visual ao <em>traceplot</em> de trajetórias realizadas com valores iniciais distintos seja o suficiente. Em termos de teoria da decisão, é sempre melhor aumentar o tamanho das trajetórias para descartar mais observações no <em>burn-in</em> do que evitar o custo computacional e fazer inferências com uma amostra que não represente <span class="math inline">\(f(x)\)</span>.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.5</strong></span> Voltando ao nosso exemplo, vamos simular 5 cadeias, com os valores iniciais <span class="math inline">\(\{-10,-5,0,5,10\}\)</span>. Abaixo seguem as trajetórias simuladas e seus respectivos <em>traceplots</em> (por didática, vamos colocar apenas as 100 primeiras iterações).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">5000</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>trajetorias <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>, <span class="fu">c</span>(<span class="dv">5000</span>,<span class="dv">5</span>))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>trajetorias[<span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>,<span class="sc">-</span><span class="dv">5</span>,<span class="dv">0</span>,<span class="dv">5</span>,<span class="dv">10</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,] <span class="ot">&lt;-</span> .<span class="dv">7</span><span class="sc">*</span>trajetorias[i<span class="dv">-1</span>,] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">5</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>(trajetorias[<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>,], <span class="at">col =</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">xlab =</span> <span class="st">'Iterações'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Observe que as trajetórias já estão em equilíbrio após poucas iterações. Como é uma simulação barata, podemos fazer um <em>burn-in</em> das primeiras 20 simulações sem prejuízos.</p>
</div>
<p>Lembremos que o objetivo da simulação estocástica sob a ótica deste curso é simular variáveis independentes e identicamente distribuídas de uma distribuição alvo. Já o objetivo de um método MCMC é gerar variáveis dependentes e identicamente distribuídas segundo a distribuição alvo. É importante ressaltar que o uso moderno dos métodos do tipo MCMC consideram a dependência como uma característica natural e as inferências utilizam esse aspecto (veremos mais sobre isso no capítulo sobre Integração de Monte Carlo). Contudo, como nosso objetivo nesta seção é a obtenção de amostras iid, essa dependência deve ser minimizada.</p>
<p>Considerando as variáveis simuladas (após o burn-in) <span class="math inline">\(x_1,x_2\ldots,x_n\)</span>, a dependência (linear) das variáveis obtidas via MCMC é estimada pela função de autocorrelação:</p>
<p><span class="math display">\[r(h)=\frac{\sum_{i=1}^{n-h}(x_i−\bar{x})(x_{i+h}−\bar{x})}{\sum_{i=1}^n (x_i−\bar{x})^2.\]</span></p>
<p>Para termos uma amostra de variáveis aproximadamente independentes, podemos remover o efeito da autocorrelação encontrando o valor <span class="math inline">\(h′\)</span> tal que <span class="math inline">\(r(h′)\approx 0\)</span> e tormar ficar somente com as variáveis <span class="math inline">\(x_1,x_{1+h′},x_{1+2h′},\ldots\)</span>. Esse processo é conhecido como <em>thinning</em>. O <em>traceplot</em> desta subamostra deve apresentar os pontos em torno da média mas sem um padrão.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.6</strong></span> Voltemos ao exemplo anterior. Após um <em>burn-in</em> de vinte observações, temos os seguintes <em>traceplots</em></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>(trajetorias[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>),], <span class="at">col =</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>A figura abaixo apresenta as autocorrelações da trajetória 1. Note que após a defasagem(lag) 15, as autorrelações podem ser consideradas nulas.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">acf</span>(trajetorias[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>),<span class="dv">1</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Autocorrelations of series 'trajetorias[-(1:20), 1]', by lag

     0      1      2      3      4      5      6      7      8      9     10 
 1.000  0.692  0.469  0.316  0.218  0.158  0.121  0.092  0.062  0.045  0.027 
    11     12     13     14     15     16     17     18     19     20     21 
 0.017  0.017  0.023  0.017  0.016  0.014  0.014  0.010  0.002 -0.005 -0.021 
    22     23     24     25     26     27     28     29     30     31     32 
-0.030 -0.041 -0.036 -0.031 -0.030 -0.021 -0.021 -0.017 -0.006 -0.008  0.003 
    33     34     35     36 
 0.014  0.022  0.018  0.011 </code></pre>
</div>
</div>
<p>Portanto, podemos eliminar essa autocorrelação com um <em>thinning</em> de tamanho 15 (ou seja, guardamos uma em cada 15 pontos da simulação). As figuras abaixo apresentam os <em>traceplots</em> das simulações finais após o burn-in e o thinning. A autocorrelação para a simulação baseada na trajetória 1 também é apresentada.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>amostra_final <span class="ot">&lt;-</span> trajetorias[ <span class="fu">seq</span>(<span class="dv">21</span>,n, <span class="dv">15</span>), ]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>(amostra_final,<span class="at">col=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(amostra_final[,<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-6-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Por último, podemos reunir todas as simulações em um único vetor, gerando nossa amostra final. Abaixo, apresentamos um histograma em conjunto com a densidade da distribuição estacionária.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>amostra <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(amostra_final)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(amostra, <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">5</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dnorm</span>(x,<span class="dv">0</span>,<span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="fl">-.3</span><span class="sc">^</span><span class="dv">2</span>))), <span class="at">add =</span> T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<p>É comum que a convergência seja checada através do comportamento do <em>traceplot</em>. Entretanto, é possível que este se comporte como o esperado sem que a convergência tenha sido atingida.</p>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.7</strong></span> Considere o núcleo de transição</p>
<p><span class="math display">\[k(x|y)=\phi(x|\frac{y}{2}+5,1)I_{(7,\infty)}(y)+\phi(x|\frac{y}{2},1)I_{(−\infty,7]}(y),\]</span> onde <span class="math inline">\(\phi(.|\mu,\sigma^2)\)</span> é a função densidade da distribuição Normal<span class="math inline">\((\mu,\sigma^2)\)</span>. Esta cadeia exibe dois comportamentos distintos, dependendo do valor de <span class="math inline">\(x_0\)</span></p>
<ul>
<li><p>Se <span class="math inline">\(x_0\)</span> está próximo de 0, a cadeia deve ser comportar como uma distribuição Normal(0,1). Neste caso, a probabilidade da cadeia gerar um valor superior a 7 é de <span class="math inline">\(1,2×10^{−12}\)</span>, o que implica que, ela deve permanecer nesta distribuição para fins práticos de simulação.</p></li>
<li><p>se <span class="math inline">\(x_0\)</span> está proximo ( ou é superior a ) de 10, é possível que a cadeia se comporte como uma Normal(10,1) por um período de tempo, como se estivesse atingido o equilíbrio. Entretanto, como há uma probabilidade de 0,13% da cadeia gerar um valor inferior a 7, eventualmente a cadeia vai abandonar este comportamento e vai convergir para a Normal(0,1).</p></li>
</ul>
<p>Abaixo segue um exemplo com <span class="math inline">\(x_0=10\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="cf">function</span>(y){ <span class="fu">ifelse</span> ( y <span class="sc">&gt;</span> <span class="dv">7</span> ,x <span class="ot">&lt;-</span> .<span class="dv">5</span><span class="sc">*</span>y <span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">1</span>) ,x <span class="ot">&lt;-</span> .<span class="dv">5</span><span class="sc">*</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">5</span>) ) </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  x </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># simulador da cadeia</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="cf">function</span>(y){</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span> ( y <span class="sc">&gt;</span> <span class="dv">7</span> ,x <span class="ot">&lt;-</span> .<span class="dv">5</span><span class="sc">*</span>y <span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">1</span>) ,x <span class="ot">&lt;-</span> .<span class="dv">5</span> <span class="sc">*</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,.<span class="dv">5</span>) )</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>x</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># simulando uma tragetória</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">600</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  x[i] <span class="ot">&lt;-</span> <span class="fu">k</span>(x[i<span class="dv">-1</span>])</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># traceplot</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>(x, <span class="at">main =</span> <span class="st">"Traceplot"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Portanto, se considerarmos um traceplot com as primeiras 200 iterações, podemos acreditar que estamos simulando da distribuição estacionária, quando na verdade esta ainda não foi atingida.</p>
</div>
<p>O exemplo acima ilustra a necessidade prática de gerar diversas cadeias com valores iniciais distintos. Quando todas as trajetórias estiverem na mesma região, teremos evidências de que a distribuição estacionária foi atingida. Contudo, a análise gráfica é subjetiva e métodos mais robustos são necessários. Para tanto, é comum o uso da estatística <span class="math inline">\(R\)</span> de Gelman-Rubin. Seja <span class="math inline">\(M\)</span> o número de cadeias utilizadas, todas de tamanbho <span class="math inline">\(n\)</span>. Então, a estatística <span class="math inline">\(R\)</span> é dada por</p>
<p><span class="math display">\[R=\sqrt{\frac{\hat{\sigma}^2}{s^2}},\]</span> onde <span class="math inline">\(s_j^2\)</span> é a variância amostral da <span class="math inline">\(j\)</span>-ésima trajetória, <span class="math display">\[s^2= \frac{1}{M}\sum_{j=1}^M s_j^2\]</span> é a média das variâncias, <span class="math inline">\(B/n\)</span> é a variância entre as médias amostrais das trajetórias, ou seja <span class="math display">\[\frac{B}{n}=\frac{1}{M-1}\sum_{j=1}^M(\bar{x}_j-\bar{x})^2,\]</span> onde <span class="math inline">\(\bar{x}_j\)</span> é a média da <span class="math inline">\(j\)</span>-ésima trajetória e <span class="math inline">\(\bar{x}\)</span> é a média geral, considerando todas as cadeias. Por último, <span class="math display">\[\hat{\sigma}^2=\frac{n-1}{n}s^2+\frac{B}{n}.\]</span></p>
<p>Como <span class="math inline">\(s^2\)</span> subestima <span class="math inline">\(σ^2\)</span>, o valor de <span class="math inline">\(R\)</span> deve ser, em geral, maior que 1. Entretanto, como os dois são consistentes, temos que <span class="math inline">\(R\)</span> decresce para 1. Portanto, teremos evidências que todas as cadeias atingiram o equilíbrio se <span class="math inline">\(R\approx1\)</span>. Na prática, é comum parar a simulação quando <span class="math inline">\(R&lt;1,1\)</span>. A função abaixo implementa a estatística R.</p>
<div class="alert alert-success">
<p><strong>Estatística de Gelman-Rubin.</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>Rgelman <span class="ot">&lt;-</span> <span class="cf">function</span>(X, burnin){</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># aplicando o burn-in</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> X[<span class="sc">-</span>(<span class="dv">1</span><span class="sc">:</span>burnin),]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># tamanho da amostra após o burn-in</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># média das cadeias</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  Xm <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(X)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># média geral</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  Xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(Xm)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># variâncias amostrais</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>  S2m <span class="ot">&lt;-</span> <span class="fu">apply</span>( X, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">var</span>(x))</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># S2</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  S2 <span class="ot">&lt;-</span> <span class="fu">mean</span>(S2m)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sigma2 chapéu</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  sigma2 <span class="ot">&lt;-</span> <span class="fu">var</span>(Xm)  <span class="sc">+</span> (n<span class="dv">-1</span>)<span class="sc">*</span>S2<span class="sc">/</span>n </span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># R</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  R <span class="ot">&lt;-</span> <span class="fu">sqrt</span>( sigma2 <span class="sc">/</span> S2)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(R)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="exm-" class="alert alert-info theorem example">
<p><span class="theorem-title"><strong>Example 8.8</strong></span> Vamos refazer o exemplo anterior adicionando mais trajetórias, começando em -10,-5,0,5 e 10.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simulando 5 tragetórias</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">600</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>trajetorias <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>, <span class="fu">c</span>(n,<span class="dv">5</span>))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>trajetorias[<span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="sc">-</span><span class="dv">5</span>,<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">10</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">k</span>( trajetorias[i<span class="dv">-1</span>, <span class="dv">1</span>])</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">k</span>( trajetorias[i<span class="dv">-1</span>, <span class="dv">2</span>])</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">k</span>( trajetorias[i<span class="dv">-1</span>, <span class="dv">3</span>])</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,<span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="fu">k</span>( trajetorias[i<span class="dv">-1</span>, <span class="dv">4</span>])</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  trajetorias[i,<span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="fu">k</span>( trajetorias[i<span class="dv">-1</span>, <span class="dv">5</span>])</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="co"># traceplot</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="fu">ts.plot</span>( trajetorias, <span class="at">main =</span> <span class="st">"Traceplot"</span>,<span class="at">col=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Como podemos ver, todas as trajetórias convergiram para a mesma distribuição estacionária. Vamos aplicar um burn-in de 300 e calcular a estatística R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Rgelman</span>( trajetorias, <span class="at">burnin =</span> <span class="dv">300</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9999378</code></pre>
</div>
</div>
<p>Como <span class="math inline">\(R&lt;1,1\)</span>, temos que evidências de que a convergência foi obtida.</p>
</div>
<div class="alert alert-danger">
<p>Nas notas de aula, analisamos a seguinte cadeia de Markov, que é reversível em relação à sua distribuição estacionária:</p>
<p>Núcleo de Transição: <span class="math inline">\(X_n | X_{n-1} = y \sim \text{Uniforme}(1-y, 1)\)</span></p>
<p>Distribuição Estacionária (Alvo): <span class="math inline">\(\pi(x) = 2x\)</span>, para <span class="math inline">\(x \in (0, 1)\)</span>.</p>
<p>Embora tenhamos simulado uma única trajetória em aula, agora vamos usar esta cadeia como um método de simulação MCMC completo, aplicando todo o nosso ferramental de diagnóstico para gerar uma amostra final que se pareça com i.i.d.</p>
<p>Objetivo: Gerar uma amostra final de tamanho agregado de pelo menos 1.000 que represente a distribuição <span class="math inline">\(\pi(x) = 2x\)</span>, seguindo todas as boas práticas de diagnóstico.Tarefas</p>
<ol type="1">
<li><p>Geração das Cadeias (Simulação)Gere <span class="math inline">\(M=5\)</span> cadeias de Markov independentes usando o núcleo de transição <span class="math inline">\(\text{Uniforme}(1-y, 1)\)</span>. Cada cadeia deve ter <span class="math inline">\(n=2000\)</span> iterações. Armazene os resultados em uma matriz trajetorias de dimensão (2000, 5).</p></li>
<li><p>Análise de Convergência (Burn-in e <span class="math inline">\(\hat{R}\)</span>)Análise Visual: Gere um ts.plot() das 5 cadeias (use as primeiras 100 iterações) para inspecionar a convergência. Análise Quantitativa: Use a função Rgelman fornecida em aula. Calcule o <span class="math inline">\(\hat{R}\)</span> para as trajetorias usando um burnin = 0. Calcule o <span class="math inline">\(\hat{R}\)</span> novamente, mas agora com um burnin = 50. O valor é <span class="math inline">\(&lt; 1.1\)</span>? Com base nisso, determine um tamanho de burn-in adequado</p></li>
<li><p>Análise de Dependência (Thinning) Após identificar o burn-in, pegue a primeira cadeia (coluna 1 de trajetorias) após o burn-in.Gere o gráfico da Função de Autocorrelação (acf()) para esta cadeia (pós-burn-in). Determine um intervalo de thinning (<span class="math inline">\(h\)</span>) apropriado</p></li>
<li><p>Entrega da Amostra Final (Processamento) Crie sua amostra final seguindo todo o processo: Remova o burnin (que você decidiu no passo 2) de todas as 5 cadeias. Aplique o thinning (com o <span class="math inline">\(h\)</span> que você escolheu no passo 3) a todas as 5 cadeias. Junte as amostras restantes das 5 cadeias em um único vetor</p></li>
</ol>
<p>Verificação Final: Plote um histograma (hist(…, freq = FALSE)) da sua amostra_final. Sobreponha a curva da distribuição estacionária teórica (use curve(2*x, from=0, to=1, add = T, col = “red”, lwd = 2)). O histograma da sua simulação representa bem a distribuição-alvo <span class="math inline">\(\pi(x) = 2x\)</span>?</p>
</div>
</section>
<section id="o-método-metropolis-hastings" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="o-método-metropolis-hastings"><span class="header-section-number">8.3</span> O método Metropolis-Hastings</h2>
<p>Seja <span class="math inline">\(f(x)\)</span> a função densidade alvo. O algoritmo Metropolis-Hastings é definido abaixo.</p>
<div class="alert alert-success">
<p><strong>Algoritmo Metropolis-Hastings</strong></p>
<p>Comece com <span class="math inline">\(x_0\)</span> arbitrário. Na <span class="math inline">\(i\)</span>-ésima iteração:</p>
<ol type="1">
<li><p>Gere <span class="math inline">\(y\sim q(.|x_{i−1})\)</span> e <span class="math inline">\(u\)</span>∼Uniforme(0,1)</p></li>
<li><p>Encontre</p></li>
</ol>
<p><span class="math display">\[\rho(x_{i−1},y)=\min\left\{1,\frac{f(y)}{f(x_{i−1})}\frac{q(x_{i−1}|y)}{q(y|x_{i−1})}\right\}.\]</span></p>
<p>Se <span class="math inline">\(u&lt;\rho(x_{i−1},y)\)</span> então <span class="math inline">\(x_i=y\)</span>. Senão, <span class="math inline">\(x_i=x_{i−1}\)</span>.</p>
</div>
<p>O Metropolis-Hastings é um método do tipo MCMC que se utiliza da densidade <span class="math inline">\(q(.|.)\)</span>, denominada proposta, para gerar estados para a cadeia de Markov. Os valores gerados pela proposta são denominados candidatos. Em cada iteração a cadeia pode permanecer no estado atual, ou fazer um movimento para o candidto gerado.</p>
<p>Vamos provar que o Metropolis-Hastings é um MCMC. Notemos que a probabilidade de transição é dada por</p>
<p><span class="math display">\[P(X_i\in A|X_{i−1}=x_{i−1})=\int_\mathbb{R^d}P(X_i\in A|X_{i−1}=x_{i−1},Y=y)q(y|x_{i−1})dy\]</span> Agora, dados <span class="math inline">\(x_{i−1}\)</span> e <span class="math inline">\(y\)</span>, sabemos que</p>
<p><span class="math display">\[xi=\left\{\begin{array}{ll}y,&amp; \hbox{ com probabilidade } \rho(x_{i−1},y)\\ x_{i−1},&amp;  \hbox{ com probabilidade } 1−\rho(x_{i−1},y)\end{array}\right.\]</span> logo <span class="math display">\[P(X_i\in A|X_{i−1}=x_{i−1},Y=y)=I_A(y)\rho(x_{i−1},y)+I_A(x_{i−1})(1−\rho(x_{i−1},y))\]</span></p>
<p>Assim, a probabilidade de transição pode ser expressada por</p>
<p><span class="math display">\[\begin{align}P(X_i\in A|X_{i−1}=x_{i−1})&amp;=\int_{\mathbb{R}^d}I_A(y)\rho(x_{i−1},y)q(y|x_{i−1})dy\\&amp;+\int_{\mathbb{R}^d}I_A(x_{i−1})(1−\rho(x_{i−1},y))q(y|x_{i−1})dy\\&amp;=\int_A \rho(x_{i−1},y)q(y|x_{i−1})dy+I_A(x_{i−1})r(x_{i−1})\end{align}\]</span> onde <span class="math display">\[r(x_{i−1})=\int_{\mathbb{R}^d}(1−\rho(x_{i−1},y))q(y|x_{i−1})dy.\]</span> Se <span class="math inline">\(f(y)q(x_{i−1}|y)&gt;f(x_{i−1})q(y|x_{i−1})\)</span>, então <span class="math inline">\(\rho(x_{i−1},y)=1\)</span> e <span class="math inline">\(r(x_{i−1})=0\)</span>. Então, <span class="math inline">\(r(x_{i−1})\)</span> pode ser reescrito como</p>
<p><span class="math display">\[r(x_{i−1})=\int_{y:f(y)q(x_{i−1}|y)&lt;f(x_{i−1})q(y|x_{i−1})}(1−\rho(x_{i−1},y))q(y|x_{i−1})dy.\]</span></p>
<p>Vamos mostrar que a cadeia de Markov definida com essa probabilidade de transição tem distribuição estacionária <span class="math inline">\(f(x)\)</span>. A demonstração será dividida em duas partes.</p>
<p><strong>Parte 1.</strong></p>
<p>Primeiro, note que esta probabilidade é uma variável aleatória mista, com a parte contínua dada por <span class="math display">\[k(y|x_{i−1})=\rho(x_{i−1},y)q(y|x_{i−1}).\]</span></p>
<p>Em relação à <span class="math inline">\(y\)</span> e <span class="math inline">\(x_{i−1}\)</span> há duas possibilidades: ou <span class="math inline">\(f(x_{i−1})q(y|x_{i−1})&lt;f(y)q(x_{i−1}|y)\)</span> ou <span class="math inline">\(f(x_{i−1})q(y|x_{i−1})&gt;f(y)q(x_{i−1}|y)\)</span>. Sem perda de generalidade, assuma que <span class="math inline">\(f(x_{i−1})q(y|x_{i−1})&gt;f(y)q(x_{i−1}|y)\)</span>. Então,</p>
<p><span class="math display">\[\rho(x_{i−1},y)=\frac{f(y)}{f(x_{i−1})}\frac{q(x_{i−1}|y)}{q(y|x_{i−1})}\]</span> e <span class="math display">\[\rho(y,x_{i−1})=1.\]</span> Da definição de <span class="math inline">\(k(.|.)\)</span>, teremos</p>
<p><span class="math display">\[\begin{align}k(y|x_{i−1})&amp;=\rho(x_{i−1},y)q(y|x_{i−1})=\frac{f(y)}{f(x_{i−1})}\frac{q(x_{i−1}|y)}{q(y|x_{i−1})}q(y|x_{i−1})\\&amp;=\frac{f(y)}{f(x_{i−1})}{q(x_{i−1}|y)}\Rightarrow(x_{i−1})k(y|x_{i−1})=f(y)q(x_{i−1}|y)\end{align}\]</span></p>
<p>Além disso, <span class="math inline">\(k(x_{i−1}|y)=\rho(y,x_{i−1})q(x_{i−1}|y)=q(x_{i−1}|y)\)</span>. Disto, temos</p>
<p><span class="math display">\[f(x_{i−1})k(y|x_{i−1})=f(y)q(x_{i−1}|y)⇒f(x_{i−1})k(y|x_{i−1})=f(y)k(x_{i−1}|y)\]</span> logo, como estão satisfeitas as equações de balanço detalhado, uma cadeia com núcleo de transição <span class="math inline">\(k(.|.)\)</span> tem distribuição estacionária <span class="math inline">\(f(.)\)</span></p>
<p><strong>Parte 2</strong></p>
<p>Agora vamos concluir a demonstração. Anteriormente, vimos as equações de balanço para uma cadeia com distribuição um passo à frente estritamente contínua. Para uma cadeia de Markov com distribuição mista, as equações de balanço detalhado são dadas por</p>
<p><span class="math display">\[\int_A P(X_i\in B|x_{i−1}=y)f(y)dy=\int_B P(X_i\in A|x_{i−1}=x)f(x)dx\]</span></p>
<p>Para a nossa cadeia, temos que</p>
<p><span class="math display">\[\begin{align}\int_AP(X_i\in B|x_{i−1}=x_{i−1})f(x_{i−1})dx_{i−1}&amp;=\int_A\int_ B\rho(x_{i−1},w)q(y|x_{i−1})f(x_{i−1})dwdx_{i−1}\\&amp;+\int_AI_B(x_{i−1})r(x_{i−1})f(x_{i−1})dx_{i−1}\\&amp;=\int_A\int_B k(w|x_{i−1})f(x_{i−1})dwdx_{i−1}+\int_BI_A(x_{i−1})r(x_{i−1})f(x_{i−1})dx_{i−1}\\&amp;=\int_B\int_A k(x_{i−1}|w)f(w)dx_{i−1}dw+\int_BI_A(w)r(w)f(w)dw=\int_B\left[\int_Ak(x_{i−1}|w)dx_{i−1}+I_A(w)r(w)\right]f(w)dw=\int_B\int_A\rho(w,x_{i−1})q(x_{i−1}|w)f(w)dx_{i−1}dw+\int_BI_A(w)r(w)f(w)dw=\int_BP(X_i\in A|x_{i−1}=w)f(w)dw\end{align}\]</span></p>
<section id="a-escolha-da-proposta-e-o-parâmetro-tunning" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="a-escolha-da-proposta-e-o-parâmetro-tunning"><span class="header-section-number">8.3.1</span> A escolha da proposta e o parâmetro <em>tunning</em></h3>
<p>Para que a cadeia de Markov de um Metropolis-Hastings tenha uma distribuição estacionária é suficiente que</p>
<ol type="1">
<li><p><span class="math inline">\(q(y|x)&gt;0\)</span> para todo <span class="math inline">\((x,y)\in S^2\)</span> , onde <span class="math inline">\(S\)</span> é o suporte de <span class="math inline">\(f(.)\)</span></p></li>
<li><p>A probabilidade do evento <span class="math inline">\({X_t=X_{t−1}}\)</span> é maior que zero.</p></li>
</ol>
<p>A primeira condição garante que a cadeia é irredutível (ou seja, que é possível partir de qualquer subconjunto <span class="math inline">\(B\subset S\)</span> e chegar em qualquer <span class="math inline">\(A\subset S\)</span> em um número finito de iterações). A segunda condição acima garante que a cadeia é aperiódica.</p>
<p>A segunda condição está associada com o passo de aceitação da cadeia. Por isso, não é desejável que todos os candidatos gerados pela proposta sejam aceitos.</p>
<p>As duas condições parecem ser facilmente satisfeitas, mas a primeira condição merece atenção. Considere que desejamos criar um gerador para a seguinte função densidade:</p>
<p><span class="math display">\[f(x)=\frac{625}{1896}\sin(x)^2x^3e^{−x},\]</span> com <span class="math inline">\(x&gt;0\)</span>. O gráfico dessa função é dado abaixo. Note que a densidade alvo possui várias modas (infinitas, na verdade). Destacamos as quatro modas mais relevantes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># densidade alvo</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">sin</span>(x)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> x<span class="sc">^</span><span class="dv">3</span> <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span>x)<span class="sc">*</span><span class="dv">625</span><span class="sc">/</span><span class="dv">1896</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># gráfico</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">f</span>(x), <span class="dv">0</span>, <span class="dv">15</span> , <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># modas</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>moda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.865</span>,<span class="fl">4.544</span>,<span class="fl">7.561</span>,<span class="fl">10.65</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>f_moda <span class="ot">&lt;-</span> <span class="fu">f</span>(moda)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>( moda, f_moda, <span class="at">pch =</span> <span class="dv">16</span>) </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>xx <span class="ot">&lt;-</span> <span class="fu">cbind</span>(moda,<span class="dv">0</span>,moda, f_moda) </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>( xx[,<span class="dv">1</span>], xx[,<span class="dv">2</span>], xx[,<span class="dv">3</span>], xx[,<span class="dv">4</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Vamos considerar como proposta a função densidade da distribuição <span class="math inline">\(Y|X=x\sim\)</span>Gama(<span class="math inline">\(x^2/\sigma^2,x/\sigma^2\)</span>) . Notemos que</p>
<p><span class="math display">\[E(Y|x)=x,\;\;Var(Y|x)=σ^2\]</span> logo, a variância da proposta é controlada por <span class="math inline">\(\sigma^2\)</span> (reparametrizar a proposta em termos de média e variância é uma estratégia muito comum em um Metropolis-Hastings).</p>
<p>A variância <span class="math inline">\(\sigma^2\)</span> tem como objetivo controlar a probabilidade de aceitação e, em alguns contextos, recebe o nome de <em>tunning parameter</em> (parâmetro de afinação). Esse nome se deve ao fato de que:</p>
<ul>
<li><p>Se <span class="math inline">\(\sigma^2\)</span> é muito alto, então valores em regiões de baixa probabilidade serão gerados com mais frequência, fazendo com que o algoritmo demore para aceitar um ponto.</p></li>
<li><p>Se <span class="math inline">\(\sigma^2\)</span> é muito baixo, os valores simulados podem ficar presos em uma moda, sem conseguir explorar outras regiões com alta densidade.</p></li>
</ul>
<p>Portanto, <span class="math inline">\(\sigma^2\)</span> deve ser escolhido de tal sorte que a cadeia consiga explorar todas as partes relevantes da distribuição com uma taxa de aceitação razoável.</p>
<p>Para ilustrar os conceitos discutidos até este momento, considere a seguinte implementação de um Metropolis-Hastings, em função de <span class="math inline">\(\sigma^2\)</span> . Nesta função, aplicamos um <em>burn-in</em> removendo a metade das simulações. Depois, detectamos a menor defasagem (lag) que retorna uma autocorrelação menor que 0,01 e utilizamos esse valor para amostrar sistematicamente os pontos restantes (<em>thinning</em>). Vamos iniciar no valor <span class="math inline">\(x0=1,8\)</span> que está bem próximo da moda com maior densidade. Por último, esta função gera 4 gráficos, organizados em duas linhas e duas colunas. Na primeira linha temos o <em>traceplot</em> e a função de autocorrelação, ambos após o <em>burn-in</em>. Na segunda linha temos o histograma a função de autocorrelação após a amostragem sistemática.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>rmetro <span class="ot">&lt;-</span> <span class="cf">function</span>(n,sigma2){ </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># vamos começar próximo da moda 1 </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fl">1.8</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># contador de aceitações </span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  contador <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a> <span class="co"># Metropolis Hastings </span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){ </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gerando um candidato </span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1</span>, x[i<span class="dv">-1</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2, x[i<span class="dv">-1</span>]<span class="sc">/</span>sigma2)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a> <span class="co"># verificando se a cadeia se move</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> <span class="fu">f</span>(y) <span class="sc">*</span> <span class="fu">dgamma</span>(x[i<span class="dv">-1</span>],y<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2,y<span class="sc">/</span>sigma2) <span class="sc">/</span>( <span class="fu">f</span>(x[i<span class="dv">-1</span>]) <span class="sc">*</span> <span class="fu">dgamma</span>(y,x[i<span class="dv">-1</span>]<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2,x[i<span class="dv">-1</span>]<span class="sc">/</span>sigma2) )</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>  rho <span class="ot">&lt;-</span> <span class="fu">min</span> (<span class="dv">1</span>, alpha)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span>( <span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> rho, {x[i] <span class="ot">&lt;-</span> y ; contador <span class="ot">&lt;-</span> contador <span class="sc">+</span><span class="dv">1</span> }, x[i] <span class="ot">&lt;-</span> x[i<span class="dv">-1</span>])</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># trajetória simulada após o bur-in </span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>  xb <span class="ot">&lt;-</span> x[ <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">:</span>(n<span class="sc">/</span><span class="dv">2</span>) )]</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># detectando o lag de interesse </span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>  aa <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">unlist</span>(<span class="fu">acf</span>(xb,<span class="at">lag =</span> (n<span class="sc">/</span><span class="dv">2</span>), <span class="at">plot =</span> <span class="cn">FALSE</span>))[<span class="dv">1</span><span class="sc">:</span>(n<span class="sc">/</span><span class="dv">2</span>)]) </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>  l <span class="ot">&lt;-</span> <span class="fu">which</span>( aa <span class="sc">&lt;</span> .<span class="dv">01</span> )</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a> <span class="co"># amostra final </span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> xb[<span class="fu">seq</span>(<span class="dv">1</span>,<span class="fu">length</span>(xb),l[<span class="dv">1</span>])]</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"% aceitação "</span>, <span class="dv">100</span><span class="sc">*</span>contador<span class="sc">/</span>n,<span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Tamanho final da amostra "</span>, <span class="fu">length</span>(x),<span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a> <span class="fu">layout</span>( <span class="fu">matrix</span>( <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">4</span>),<span class="dv">2</span>,<span class="dv">2</span>)) </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a> <span class="co"># trajetória simulada após o burn-in </span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a> <span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)) </span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a> <span class="fu">ts.plot</span>(x, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="co"># função de autocorrelação estimada</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)) </span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(xb)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="co"># histograma</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)) </span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x, <span class="at">freq =</span> F, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">35</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">15</span>), <span class="at">sub=</span> <span class="fu">expression</span>(sigma<span class="sc">^</span><span class="dv">2</span><span class="sc">==</span><span class="dv">1</span>), <span class="at">main =</span> <span class="st">""</span>)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">f</span>(x), <span class="at">add =</span> T, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="co"># função de autocorrelação estimada</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)) </span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(x)</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Vamos simular uma amostra aleatória de <span class="math inline">\(X\)</span> utilizando o algoritmo Metropolis-Hastings com a proposta acima, utilizando <span class="math inline">\(\sigma^2\in\{0,1\;\;,\;\;16\;\;,\;\;200\}\)</span> , criando os cenários abaixo. Em todos os cenários foram geradas trajetórias de tamanho 100.000</p>
<div class="alert alert-info">
<p><strong>Cenário 1</strong>: <span class="math inline">\(\sigma^2=16\)</span>. Neste cenário a função de autocorrelação após o <em>burn-in</em> decai exponencialmente. Deste modo, grande parte dos 50.000 valores simulados farão parte da amostra final, que tem tamanho superior a 1.000.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmetro</span>(<span class="dv">100000</span>, <span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>% aceitação  26.447 
Tamanho final da amostra  1220 </code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="alert alert-info">
<p><strong>Cenário 2</strong>: <span class="math inline">\(\sigma^2=0,1\)</span>. Neste cenário a função de autocorrelação após o <em>burn-in</em> decai de modo quase linear, como em um processo não estacionário (com tendência). Isto faz com que a amostra final tenha um tamanho pouco maior que 20. Além disso, a proposta tem dificuldades em explorar todo o suporte, conforme podemos ver no histograma.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmetro</span>(<span class="dv">100000</span>, .<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>% aceitação  81.159 
Tamanho final da amostra  35 </code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="alert alert-info">
<p><strong>Cenário 3</strong>: <span class="math inline">\(\sigma^2=200\)</span>. Neste cenário a função de autocorrelação após o <em>burn-in</em> decai hiperbolicamente, lembrando um processo estacionário de longa dependência.Esse comportamento faz com que poucas amostras sejam retidas, nos levando a um elevado custo computacional se comparado com o cenário 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rmetro</span>(<span class="dv">100000</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>% aceitação  5.785 
Tamanho final da amostra  107 </code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="mcmc_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</div>
<p>Diversos estudos sugerem que a variância da proposta deve ser ajustada para ter uma aceitação de aproximadamente 1/4. Fica como sugestão de leitura o trabalho pioneiro:</p>
<p>Roberts, G.O., Gelman, A., Gilks, W.R. (1997). Weak Convergence and Optimal Scaling of Random Walk Metropolis Algorithms. Ann. Appl. Probab. 7, 110-20.</p>
<div class="alert alert-danger">
<p><strong>Exercício</strong> Considere a densidade</p>
<p><span class="math display">\[f(x)=k\sin(x^2)^2e^{-x^2/2},\]</span> onde <span class="math inline">\(x\in\mathbb{R}\)</span> e <span class="math inline">\(k\)</span> é a constante de normalização. Considerando a proposta <span class="math inline">\(Y|x\sim\hbox{Normal}(x,\tau)\)</span>, onde <span class="math inline">\(\tau\)</span> é o <em>tunning parameter</em>, construa um algoritmo do tipo Metropolis-Hastings para obter amostras de <span class="math inline">\(f(x)\)</span>.</p>
</div>
<!-- ### O método Metropolis  -->
<!-- O método Metropolis é um caso particular do Metropolis-Hastings com $q(x|y)=q(y|x). Com esta variação o algoritmo se torna: -->
<!-- <div class='alert alert-success'> -->
<!-- **Algoritmo Metropolis** -->
<!-- Inicie a cadeia com $x_0$ . Na $k$-ésima iteração: -->
<!-- 1. Gere $y\sim q(.|x_{k−1})$ e $u\sim$Uniforme(0,1) . -->
<!-- 2. Calcule $\rho(x_{k−1},y)=\min\{1,\frac{f(y)}{f(x_{k−1})}\}$ -->
<!-- 3. Faça -->
<!-- $$x_k=\left\{\begin{array}{ll}y,& \hbox{ se } u\leq \rho(x_{k−1},y)\\ x_{k−1}, \hbox{ se } u\>\rho(x_{k−1},y)\\ \end{array}$$ -->
<!-- Uma das vantagens deste método é o uso da distribuição normal multivariada como proposta para a geração de vetores aleatórios. Abaixo seguem algumas dicas para melhorar a convergência desse método: -->
<!-- Determine as modas da distribuição alvo. Utilize-as como valores iniciais -->
<!-- Calcule a matriz Hessiana de $−\logf(x)$ , aplicada nas modas. Denotando-a por $\mathcal{H}$ , utilize-a na seguinte proposta: -->
<!-- $$y\sim N(x_{k−1},\tau\mathcal{H}^{−1}),$$ -->
<!-- onde $\tau$ é o *tunning parameter*. -->
<!-- Suponha que desejamos simular um vetor de dimensão $d$. Se o suporte de $d$ não for o $\mathbb{R}^d$ , considere uma transformação monótona $g(.)$ com imagem em $\mathbb{R}^d$ . Faça $z=g(x)$ e simule primeiramente os valores de $z$ , cuja densidade é $f_Z(z)=f(g^{−1}(x))|\mathcal{J}|$, onde $|\mathcal{J}|$ é o módulo do determinante do jacobiano da transformação. Em seguida, utilize $g^−{1}(.)$ para obter amostras de $X$. -->
<!-- Exemplo 12.1 -->
<!-- Considere a função densidade f(x)=23(1+cos(x))e−x com x\>0 . Abaixo segue um esboço dessa função. -->
<!-- fx \<- function(x) (2/3) \* (1+cos(x)) \* exp(-x) curve( fx(x), 0,5, lwd = 2) -->
<!-- Vamos simular uma amostra aleatória desta distribuição utilizando o método Metropolis. Note que o suporte de f(.) não está na reta. Considere a variável transformada Z=log(X) , cuja densidade fZ(z)=f(ez)ez, com z∈R . Abaixo segue um esboço dessa densidade -->
<!-- fz \<- function(z) exp(z) \* fx( exp(z)) curve( fz(x), -4,4 , lwd = 2) -->
<!-- Vamos simular primeiro valores de fZ(.) através do método Metropolis. -->
<!-- Vamos determinar a moda principal de fZ(.) para utilizar como valor inicial e a hessiana de −logfZ(z) para construir a variância da proposta. Para encontrar as modas de uma função e sua respectiva matriz hessiana, o R conta com a função optim. Trata-se de um minimizador local com vários métodos implementados. Ela possui diversos parâmetros, sendo os principais: -->
<!-- par: valores iniciais, de preferência próximos dos mínimos locais. -->
<!-- fn: função objetivo. -->
<!-- method: é o algoritmo de otimização. -->
<!-- hessian: lógico. Se igual a TRUE a matriz hessiana é computada aplicada no mínimo local. -->
<!-- É importante reforçar que a optim serve para encontrar mínimos locais (não é como a função optimize que possui um argumento para mudar o problema para maximização). Isso é um detalhe simples de ser resolvido, uma vez que maximar h(x) é equivalente a minimizar −h(x) . Vamos definir nossa função objetivo como sendo −logfZ(z) . Como nosso problema é univariado, devemos utilizar o método Brent e, com isso, definir dois parâmetros adicionais, lower e upper que juntos formam um intervalo que contém o mínimo local -->
<!-- fun_objetivo \<- function(z) -log( fz(z) ) -z -->
<!-- op\<- optim( par = 0, fn = fun_objetivo, method = "Brent" , lower = -4, upper = 4, hessian = T) O objeto op contém diversas informações. As mais relevantes são par, que contém a moda; convergence, que retorna o valor 0 se o algoritmo convergiu; hessian que retorna a matriz hessiana da função objetivo. Esses três argumentos são apresentados abaixo. -->
<!-- #valor 0 indica convergência op$convergence -->
<!-- ## [1] 0 -->
<!-- # moda encontrada -->
<!-- op$par \## \[1\] 0.1754645 \# hessiana. Seu inverso será a variância da proposta op\$hessian \## \[,1\] \## \[1,\] 3.036793 Abaixo, construímos um algoritmo Metropolis para simular de fZ(.) . -->
<!-- # valor inicial -->
<!-- z \<- op\$par -->
<!-- # variância da proposta -->
<!-- s2 \<- 1/op\$hessian -->
<!-- # tunning -->
<!-- tau \<- 50 -->
<!-- # tamanho da trajetória -->
<!-- B \<- 50000 -->
<!-- # contador (para verificar a taxa de aceitação) -->
<!-- contador \<- 0 -->
<!-- # Metropolis -->
<!-- for(i in 2:B){ -->
<!-- \# gerndo y e u y \<- rnorm(1,z\[i-1\],sqrt(tau\*s2)) u \<- runif(1) -->
<!-- rho \<- min( 1, fz(y)/fz(z\[i-1\])) -->
<!-- \# movimento da cadeia ifelse( u \< rho, {z\[i\]\<- y ; contador \<- contador +1}, z\[i\] \<- z\[i-1\]) } -->
<!-- # taxa de aceitaçãp -->
<!-- contador/B \## \[1\] 0.30244 \# burn-in e autocorrelações z_burn \<- z\[-(1:(B/2))\] acf(z_burn, main ="") -->
<!-- # amostra final -->
<!-- z_sim \<- z_burn\[seq(1,length(z_burn),15)\] -->
<!-- # histograma dos valores finais -->
<!-- hist(z_sim, freq=F, ylim=c(0,.4), main ="") curve(fz(x),add=T, lwd = 2) -->
<!-- Agora que simulamos pontos de fZ(.) , podemos simular pontos de f(.) : -->
<!-- # amostra simulada de x -->
<!-- x \<- exp(z_sim) -->
<!-- # histograma da amostra simulada -->
<!-- hist(x, freq=F, main = "") curve(fx(x),add=T) -->
<!-- Exemplo 12.2 -->
<!-- Considere a função densidade f(x,t)=tx62(1+x)e−x(1+t) com x\>0 e t\>0 . Abaixo segue um esboço dessa função. -->
<!-- # densidade alvo. -->
<!-- fxt \<- function(x) x\[1\]\^6 *x\[2\]* ( 1 + x\[1\] ) \* exp( -x\[1\] \* ( 1 + x\[2\] ) ) /2 -->
<!-- # gráfico de contorno -->
<!-- x1 \<- seq(.5,12,.01) x2 \<- seq(0,5,.1) imx \<- outer( x1, x2, function(x1,x2) apply( cbind(x1,x2),1,fxt) ) contour( x1, x2, imx, ylim=c(-3,5)) -->
<!-- Vamos simular uma amostra aleatória desta distribuição utilizando o método Metropolis. O suporte de f(.) não está em R2 . Considere o vetor transformado Z1=log(X1) e Z2=log(X2) , cuja densidade -->
<!-- fZ(z)=f(ez1,ez2)ez1+z2, com z∈R2 . Abaixo segue um esboço dessa densidade -->
<!-- # densidade de Z = log(X) -->
<!-- fz \<- function(z) exp( z\[1\]+z\[2\] ) \* fxt( c(exp(z\[1\]),exp(z\[2\])) ) -->
<!-- # gráfico de contorno -->
<!-- z1 \<- seq(-1,3,.1) z2 \<- seq(-3,2,.1) imz \<- outer( z1, z2, function(z1,z2) apply( cbind(z1,z2),1,fz) ) contour( z1, z2, imz) -->
<!-- Vamos simular primeiro valores de fZ(.) através do método Metropolis. Primeiro, encontraremos a moda da densidade e a matriz hessiana que será utilizada para construir a matriz de covariâncias da proposta. -->
<!-- fun_objetivo \<- function(z) -log( fz(z) ) -->
<!-- op\<- optim( par = c(0,0), fn = fun_objetivo, hessian = T) Os argumentos relevantes contidos em op para este exemplo são apresentados abaixo. -->
<!-- #valor 0 indica convergência op$convergence -->
<!-- ## [1] 0 -->
<!-- # moda encontrada -->
<!-- op$par \## \[1\] 1.767102 -1.074004 \# hessiana. Seu inverso irá compor a variância da proposta op\$hessian \## \[,1\] \[,2\] \## \[1,\] 7.729151 1.999902 \## \[2,\] 1.999902 1.999902 Abaixo, construímos um algoritmo Metropolis para simular de fZ(.) . -->
<!-- # carregango o pacote MASS, para simular normais multivariadas -->
<!-- require(MASS) -->
<!-- # tamanho da trajetória -->
<!-- B \<- 500000 -->
<!-- # valor inicial -->
<!-- z \<- array( NA_real\_, c( B , 2 )) z\[1, \] \<- op\$par -->
<!-- # variância da proposta -->
<!-- s2 \<- solve(op\$hessian) -->
<!-- # tunning -->
<!-- tau \<- 10 -->
<!-- # contador (para verificar a taxa de aceitação) -->
<!-- contador \<- 0 -->
<!-- # Metropolis -->
<!-- for(i in 2:B){ -->
<!-- \# gerando y e u y \<- mvrnorm(1, z\[i-1,\], tau \* s2 ) u \<- runif(1) -->
<!-- \# log da razao rho \<- min( 1, fz(y)/fz(z\[i-1,\]) ) -->
<!-- \# movimento da cadeia ifelse( u \< rho, {z\[i,\]\<- y ; contador \<- contador +1}, z\[i,\] \<- z\[i-1,\]) } -->
<!-- # taxa de aceitação -->
<!-- contador/B \## \[1\] 0.166738 \# burn-in e autocorrelações z_burn \<- z\[-(1:(B/2)),\] acf(z_burn, main ="") -->
<!-- # amostra final -->
<!-- z_sim \<- z_burn\[ seq(1,nrow(z_burn),30) , \] -->
<!-- # densidade estimada via valores simulados -->
<!-- contour(kde2d(z_sim\[,1\], z_sim\[,2\])) contour(z1,z2, imz, add = T ,col =4, lty = 2) legend("bottomleft",c("simulação","alvo"), col = c(1,4), lty=c(1,2), bty = "n") -->
<!-- Agora que simulamos pontos de fZ(.) , podemos simular pontos de f(.) : -->
<!-- # amostra simulada de x -->
<!-- x \<- exp(z_sim) -->
<!-- # densidade estimada da amostra simulada -->
<!-- contour(kde2d(x\[,1\], x\[,2\]), ylim = c(0,3) ) contour(x1, x2, imx, add = T, col = 4, lty = 2) legend("topright",c("simulação","alvo"), col = c(1,4), lty=c(1,2), bty = "n") -->
<!-- Exercícios Exercício 1 Simule, via o método Metropolis-Hastings, uma amostra aleatória de tamanho 200 da distribuição cuja função densidade é dada por f(x)=1+x222π−−√exp{−x22}, com −∞\<x\<∞ . -->
<!-- Exercícios Exercício 1 Considere as seguintes máximas anuais do Rio Negro, obtidas no Porto de Manaus -->
<!-- Ano199219931994199519961997199819992000200120022003Máxima25.4228.7629.0527.1628.5428.9627.5829.3028.6228.2128.9128.27Ano20042005200620072008200920102011201220132014Máxima27.1328.1028.8428.1828.6229.7727.9628.6229.9729.3329.50 -->
<!-- Considere que estes dados são provenientes de uma amostra aleatória do modelo Weibull, dado por f(x\|α,β)=αβ(xβ)α−1e−(xβ)α, com x,α,β\>0 . Considere a transformação θ1=log(α),θ2=log(β) e faça (θ1,θ2)∼N(02,100I2) . Sob o ponto de vista bayesiano, as inferências devem ser realizadas segundo a densidade a posteriori, dada por -->
<!-- f(θ1,θ2\|x1,…,xn)∝f(x1,…,xn\|θ1,θ2)f(θ1,θ2) 1. Construa um simulador para a posteriori acima utilizando o método Metropolis. Gere 5.000 amostras. -->
<!-- Neste ano (2021) o Rio Negro atingiu a sua máxima histórica, de 29,98 metros. Utilize as amostras geradas acima para estimar a probabilidade P(X\>29,98\|x1,…,xn) utilizando o seguinte algoritmo: -->
<!-- Para cada (θ1,θ2) gerado, simule x∗∼Weibull(eθ1,eθ2) -->
<!-- Para a amostra x∗1,\ldotos,x∗5.000 , estime a probabilidade desejada por -->
<!-- 15.000∑i=15.000I(29.98,∞)(x∗i) 3. Com base na estimativa acima, podemos dizer que a máxima de 2021 era esperada? -->
<!-- Aula 13 - O amostrador de Gibbs Considere que desejamos simular amostras aleatórias do vetor X , de comprimento d , com função densidade (ou de probabilidade) dada por fX(.) . Seja X(1),…,X(s) uma partição do vetor X , escolhida de tal sorte que sabemos simular X(j)\|X(−j)=x(−j), para j=1,…,s , onde (−j)={1,…,s}/{j} . As distribuições acima são denominadas condicionais completas. -->
<!-- Nesta situação, podemos utilizar o amostrador de Gibbs, definido a seguir. -->
<!-- Amostrador de Gibbs -->
<!-- Comece fixando o valor inicial x(−1)0 , escolhido no suporte de X(−1) . Na k -ésima iteração do algoritmo: -->
<!-- Simule x(1)k∼fX(1)\|X(−1)(.\|x(−1)k−1) -->
<!-- Simule x2(k)∼fX(2)\|X(−2)(.\|x(1)k,x(−1,−2)k−1) -->
<!-- Simule x(3)k∼fX3\|X(−3)(.\|x(1,2)k,x(−1,−2,−3)k−1) -->
<!-- \*. (…) -->
<!-- Simule x(s)k∼fX(s)\|X(−s)(.\|x(−s)k) Quando s=d , temos a formulação original do amostrador de Gibbs. Em caso contrário, dizemos temos um amostrador de Gibbs em blocos (blocked Gibbs sampler). -->
<!-- O algoritmo acima gera uma trajetória do processo {X(k),k=0,1,…} . Como X(k) é gerado a partir de X(k−1)=x(k−1) , temos que esse processo é uma Cadeia de Markov. -->
<!-- Para mostrar que o amostrador de Gibbs é um MCMC, devemos verificar que a distribuição estacionária do processo é fX(.) . Para não carregar a notação e, sem perda de generalidade, assuma que estamos interessados em simular fX,Y(.) . Na j -ésima iteração do algoritmo, teremos xtyt∼fX\|Y(.\|yt−1)∼fY\|X(.\|xt) -->
<!-- Note que o núcleo de transição desta cadeia é -->
<!-- k(xt,yt\|xt−1,yt−1)=fY\|X(yt\|xt)fX\|Y(xt\|yt−1) Como fX,Y(xt,yt)=fY\|X(yt\|xt)fX(xt)=fY\|X(yt\|xt)∫fX\|Y(xt\|yt−1)fY(yt−1)dyt−1=∫fY\|X(yt\|xt)fX\|Y(xt\|yt−1)k(xt,yt\|xt−1,yt−1)fY(yt−1)dyt−1=∫k(xt,yt\|xt−1,yt−1)fY(yt−1)dyt−1=∫k(xt,yt\|xt−1,yt−1)∫fX,Y(xt−1,yt−1)dxt−1dyt−1=∫∫k(xt,yt\|xt−1,yt−1)fX,Y(xt−1,yt−1)dxt−1dyt−1 temos que fX,Y(.,.) é, de fato, a distribuição estacionária desta cadeia. -->
<!-- Exemplo 1 -->
<!-- Considere a seguinte função densidade -->
<!-- f(x)∝exp⎧⎩⎨⎪⎪−14x′⎛⎝⎜3−1−1−13−1−1−13⎞⎠⎟x⎫⎭⎬⎪⎪∏j=13I(−2,2)(xj) ou seja X tem distribuição normal multivariada restrita ao cubo (−2,2)3 . É fácil mostrar que f(xi\|xj,xk)∝exp{−43(xi−xj+xk3)}I(−2,2)(xi) ou seja, xi\|xj,xk tem distribuição normal truncada, restrita ao intervalo (−2,2) . O amostrador de Gibbs correspondente é dado abaixo: -->
<!-- # tamanho da trajetória -->
<!-- B \<- 5000 -->
<!-- # array para guardar a trajetória -->
<!-- x \<- array(NA_real\_,c(B,3)) -->
<!-- # valor inicial (nas modas de f) -->
<!-- x\[1,\] \<- c(0,0,0) -->
<!-- # amostrador de Gibbs -->
<!-- for(i in 2:B){ -->
<!-- \# x1 dado o resto while( is.na(x\[i,1\]) == T){ y \<- rnorm(1, ( x\[i-1,2\]+x\[i-1,3\] ) /3, sqrt(2/3) ) if( {y\<2} & {y\>-2}){ x\[i,1\] \<- y } } -->
<!-- \# x2 dado o resto while( is.na(x\[i,2\]) == T){ y \<- rnorm(1, ( x\[i,1\]+x\[i-1,3\] ) /3, sqrt(2/3) ) if( {y\<2} & {y\>-2}){ x\[i,2\] \<- y } } -->
<!-- \# x3 dado o resto while( is.na(x\[i,3\]) == T){ y \<- rnorm(1, ( x\[i,1\]+x\[i,2\] ) /3, sqrt(2/3) ) if( {y\<2} & {y\>-2}){ x\[i,3\] \<- y } } -->
<!-- } -->
<!-- # amostra após o burn-in -->
<!-- burn \<- 1:(.5\*B) x_burn \<- x\[ -burn , \] -->
<!-- # autocorrelações -->
<!-- acf(x_burn) -->
<!-- # amostra final -->
<!-- m \<- nrow(x_burn) x_sim \<- x_burn\[ seq(1, m, 5) , \] -->
<!-- # traceplot e autocorrelação da amostra final -->
<!-- ts.plot(x_sim\[,1\]) -->
<!-- acf(x_sim\[,1\]) -->
<!-- É interessante notar que as distribuições marginais de X distribuição normal padrão truncada em (-2,2). Abaixo, mostramos o histograma da primeira componente simulada e sua respectiva função densidade. -->
<!-- hist(x_sim\[,1\] , freq = FALSE, main ="", xlab = expression(x\[1\])) curve( dnorm(x)/( 2\*pnorm(2)-1) , add = T, lwd = 2) -->
<!-- Exercícios Exercício 15.1 -->
<!-- Considere o modelo bivariado: -->
<!-- P(X=x\|Y=y)f(y)=(nx)yx(1−y)n−x, com x∈{0,1,…,n} e y∈(0,1) . Construa um amostrador de Gibbs para simular amostras de (X,Y) . -->
<!-- Aula 14 - Amostrador de Gibbs em blocos e colapsado Nesta aula vamos discutir algumas estratégias que podem acelerar a convergência do amostrador de Gibbs. -->
<!-- Considere o vetor aleatório (X,Y,Z) . O amostrador de Gibbs tradicional (aquele em que todas as condicionais completas são univariadas) necessita das seguintes condicionais completas: -->
<!-- Estretégia 1: amostrador de Gibbs “tradicional” xyz∼f(x\|y,z)∼f(y\|x,z)∼f(z\|x,y) Suponha que é simples simular (Y,Z) . Então, podemos propor um amostrador de Gibbs em blocos (com condicionais completas multivariadas) com as seguintes condicionais completas: -->
<!-- Estratégia 2: amostrador de Gibbs em blocos x(y,z)∼f(x\|y,z)∼f(y,z\|x) Podemos ainda inverter a ordem da simulação, criando a estratégia 3 -->
<!-- Estratégia 3: amostrador de Gibbs em blocos (trocando a ordem dos blocos) x(y,z)∼f(x\|y,z)∼f(y,z\|x) Considere agora que o problema de simular (X,Y) pode ser tratável via um amostrador de Gibbs. Especificamente, considere que fX,Y(x,y)=∫fX,Y,Z(x,y,z)dz é uma distribuição tratável via um amostrador de Gibbs. Então, podemos simular a amostra (x1,y1),…,(xm,ym) e, posteriormente, simular zi∼fZ\|X,Y(\|xi,yi) . Este método, no qual o amostrador de Gibbs é aplicado apenas a um subconjunto da partição do vetor aleatório em questão, é denominado colapsado. No exemplo acima, dizemos que o amostrador foi colapsado na variável Z . -->
<!-- Abaixo, segue a nossa estratégia 4. -->
<!-- Estretégia 4: amostrador de Gibbs colapsado xxy∼f(x\|y,z)∼f(x\|y)∼f(y\|x). Após a convergência, utilize os valores simulados para simular valores de z∼f(z\|x,y). Exemplo 14.1 -->
<!-- Seja (X,Y,Z) um vetor aleatório com distribuição normal variada com vetor de médias nulo e matriz de covariâncias dada por -->
<!-- ⎛⎝⎜⎜10,1−−−√0,8−−−√0,1−−−√100,8−−−√01⎞⎠⎟⎟. -->
<!-- É fácil simular vetores aleatórios com esta distribuição, sem a necessidade de um MCMC. Contudo, este exemplo simples nos permite verificar a eficiência da simulação utilizando as quatro estratégias acima. -->
<!-- Estratégia 1 -->
<!-- Primeiro, notemos que x\|y,zy\|x,zz\|x,y∼N(0,1−−−√y+0,8−−−√z,110)∼N(50,1−−−√x−8–√2z,12)∼N(1090,8−−−√x−8–√9z,19) -->
<!-- Abaixo simulamos uma trajetória de tamanho 50000 e guardamos os valores de sua função de autocorrelação após o burn-in: -->
<!-- # tamanho da trajetória -->
<!-- B \<- 50000 -->
<!-- # array para guardar as simulações -->
<!-- a \<- array(NA_real\_, c(B,3)) -->
<!-- # valores iniciais -->
<!-- a\[1,\] \<- c(0,0,0) -->
<!-- # amostrador de Gibbs -->
<!-- for(i in 2 : B){ \# x dado o resto muXdadoResto \<- sqrt(0.1) \* a\[i-1,2\] + sqrt(.8) \* a\[i-1,3\] a\[i,1\] \<- rnorm(1, muXdadoResto, sqrt(.1) ) -->
<!-- \# y dado o resto muYdadoResto \<- 5*sqrt(0.1)* a\[i,1\] - .5*sqrt(8)* a\[i-1,3\] a\[i,2\] \<- rnorm(1, muYdadoResto, sqrt(.5) ) -->
<!-- \# z dado o resto muZdadoResto \<- ( 10*sqrt(0.8)* a\[i,1\] - sqrt(8) \* a\[i,2\] )/9 a\[i,3\] \<- rnorm(1, muZdadoResto, sqrt( 1/9 ) ) -->
<!-- } -->
<!-- # trajetória após o burn-in -->
<!-- a_burn \<- a\[ -( 1 : (.5\*B)),\] -->
<!-- # autocorrelção de x -->
<!-- acf1 \<- acf(a_burn\[,1\], main ="", plot = F) Estratégias 2 e 3 -->
<!-- Agora, note que podemos utilizar as seguintes condicionais completas para amostrar em blocos: -->
<!-- (y,z)\|xx\|(y,z)∼N⎛⎝(0,1−−−√0,8−−−√)x,⎛⎝0,9−8√10−8√100,2⎞⎠⎞⎠∼N(0,1−−−√y+0,8−−−√z,110) -->
<!-- Abaixo simulamos uma trajetória de tamanho 5000 utilizando o amostrador de Gibbs em blocos com a Estratégia 2: -->
<!-- # pacote para simulação de normais multivariadas (entre outras funções) -->
<!-- library(MASS) -->
<!-- # tamanho da trajetória -->
<!-- B \<- 50000 -->
<!-- # array para guardar as simulações -->
<!-- a \<- array(NA_real\_, c(B,3)) -->
<!-- # valores iniciais -->
<!-- a\[1,\] \<- c(0,0,0) -->
<!-- # amostrador de Gibbs -->
<!-- for(i in 2 : B){ \# x dado o (x,z) muXdadoResto \<- sqrt(0.1) \* a\[i-1,2\] + sqrt(.8) \* a\[i-1,3\] a\[i,1\] \<- rnorm(1, muXdadoResto, sqrt(.1) ) -->
<!-- \# (y,z) dado x muYZ \<- matrix( c( sqrt(0.1), sqrt(.8) ) , ncol = 1 )\* a\[i,1\] SigmaYZ \<- matrix( c(.9, - .1*sqrt(8), -.1*sqrt(8), .2), 2,2) a\[i,2:3\] \<- mvrnorm(1, muYZ, SigmaYZ) -->
<!-- } -->
<!-- # trajetória após o burn-in -->
<!-- a_burn \<- a\[ -( 1 : (.5\*B)),\] -->
<!-- # autocorrelção de x -->
<!-- acf2 \<- acf(a_burn\[,1\], main ="", plot = FALSE) E aqui para a Estatégia 3: -->
<!-- # pacote para simulação de normais multivariadas (entre outras funções) -->
<!-- library(MASS) -->
<!-- # tamanho da trajetória -->
<!-- B \<- 50000 -->
<!-- # array para guardar as simulações -->
<!-- a \<- array(NA_real\_, c(B,3)) -->
<!-- # valores iniciais -->
<!-- a\[1,\] \<- c(0,0,0) -->
<!-- # amostrador de Gibbs -->
<!-- for(i in 2 : B){ \# (y,z) dado x muYZ \<- matrix( c( sqrt(0.1), sqrt(.8) ) , ncol = 1 )\* a\[i-1,1\] SigmaYZ \<- matrix( c(.9, - .1*sqrt(8), -.1*sqrt(8), .2), 2,2) a\[i,2:3\] \<- mvrnorm(1, muYZ, SigmaYZ) -->
<!-- \# x dado o (x,z) muXdadoResto \<- sqrt(0.1) \* a\[i,2\] + sqrt(.8) \* a\[i,3\] a\[i,1\] \<- rnorm(1, muXdadoResto, sqrt(.1) ) -->
<!-- } -->
<!-- # trajetória após o burn-in -->
<!-- a_burn \<- a\[ -( 1 : (.5\*B)),\] -->
<!-- # autocorrelção de x -->
<!-- acf3 \<- acf(a_burn\[,1\], main ="", plot = FALSE) Estratégia 4 Ao colapsar o vetor (X,Y,Z) em Z teremos que (X,Y) tem distribuição normal multivariada com vetor de médias nulo e matriz de covariâncias dada por -->
<!-- (10,1−−−√0,1−−−√1) e as condicionais completas do amostrador de Gibbs são: x\|yy\|x∼N(0,1−−−√y,910)∼N(0,1−−−√x,910) Após simular a amostra (x,y) vamos simular z através da seguinte condicional: -->
<!-- z\|x,y∼N(1090,8−−−√x−8–√9z,19) -->
<!-- Aqui mostramos a implementação da Estatégia 4 (não vamos simular Z porque nosso objetivo é comparar as funções de autocorrelação): -->
<!-- # pacote para simulação de normais multivariadas (entre outras funções) -->
<!-- library(MASS) -->
<!-- # tamanho da trajetória -->
<!-- B \<- 50000 -->
<!-- # array para guardar as simulações -->
<!-- a \<- array(NA_real\_, c(B,3)) -->
<!-- # valores iniciais -->
<!-- a\[1,\] \<- c(0,0,0) -->
<!-- # amostrador de Gibbs -->
<!-- for(i in 2 : B){ \# x dado y muX \<- sqrt(.1) \* a\[i-1,2\] SigmaX \<- .9 a\[i,1\] \<- rnorm(1, muX, sqrt( SigmaX ) ) -->
<!-- \# x dado y muY \<- sqrt(.1) \* a\[i,1\] SigmaY \<- .9 a\[i,2\] \<- rnorm(1, muY, sqrt( SigmaY ) ) -->
<!-- } -->
<!-- # trajetória após o burn-in -->
<!-- a_burn \<- a\[ -( 1 : (.5\*B)),\] -->
<!-- # autocorrelção de x -->
<!-- acf4 \<- acf(a_burn\[,1\], main ="", plot = FALSE) Comparando as 4 estratégias -->
<!-- O gráfico abaixo mostra a performance das estratégias. Podemos notar que o amostrador de Gibbs colapsado tem as menores autocorrelações. Também podemos perceber que permutar a ordem das simulações dentro do amostrador (como na comparação entre as estratégias 2 e 3) podem trazer melhorias. -->
<!-- plot(acf1$acf,main="", type="l" ,col = 1 ,ylab = "Autocorrelações", -->
<!--      xlab= "Defasagem (lag)") -->
<!-- lines(acf2$acf, col =2) lines(acf3$acf, col = 3) -->
<!-- lines(acf4$acf, col =4) legend("topright", c("Estratégia 1", "Estratégia 2", "Estratégia 3", "Estratégia 4"), col = 1:4, bty = "n", lty = 1) -->
<!-- Exercícios Exercício 14.1 -->
<!-- Considere o modelo f(x,y,z,w)=(wx)(wy)zx+y(1−z)2w−x−y, com x∈{0,…,w} , y∈{0,…,w} , w∈{1,…,10} e z∈(0,1) . -->
<!-- Mostre que as condicionais completas são z\|x,y,wx\|y,z,wy\|x,z,wf(w\|x,y,z)∼Beta(x+y+1,2w−x−y+1)∼Binomial(w,z)∼Binomial(w,z)∝(wx)(wy)(1−z)2w−x−yI{max{1,x,y},…,10}(w) -->
<!-- Construa um simulador para f(w\|x,y,z) e utilize esse resultado para construir um amostrador de Gibbs. -->
<!-- Mostre que -->
<!-- f(w\|x,y)∝(wx)(wy)B(x+y+1,2w−x−y+1)I{max1,x,y,…,10}. Utilize este resultado para construir um simulador para f(z,w\|x,y)=f(z\|x,y,w)f(w\|x,y) . -->
<!-- Com o simulador acima, construa um amostrador de Gibbs em blocos, simulando de (x,y\|z,w) e (z,w\|x,y) . -->
<!-- Compare as funções de autocovariância das amostras de Z obtidas nos dois amostradores de Gibbs e outro com a ordem -->
<!-- zwxy\|x,y,w\|x,z,w\|y,z,w\|x,w,z -->
<!-- Gere 500 trajetórias de tamanho 1000 de cada amostrador. Para cada trajetória, guarde os valores da função de autocorrelação até o lag 40. Conclua que a segunda -->


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./AR.html" class="pagination-link" aria-label="O método da aceitação/rejeição">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">O método da aceitação/rejeição</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./monte_carlo.html" class="pagination-link" aria-label="O método de integração de Monte Carlo">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">O método de integração de Monte Carlo</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>